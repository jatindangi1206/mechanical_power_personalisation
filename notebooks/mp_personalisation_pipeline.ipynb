{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ac9360",
   "metadata": {},
   "source": [
    "# Mechanical Power Personalisation for ICU Patients\n",
    "\n",
    "**End-to-end pipeline**: Data extraction → Preprocessing → MDP construction → Model training → Evaluation\n",
    "\n",
    "Three progressive strategies:\n",
    "1. **S1 — Static XGBoost** baseline (admission features)\n",
    "2. **S2 — Time-Window XGBoost** baseline (trajectory features)\n",
    "3. **S3 — Conservative Q-Learning (CQL)** offline RL agent\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e28198c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /content\n",
      "Contents: ['.config', 'sample_data']\n",
      "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "Home: /root\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 1: Environment setup\n",
    "# ============================================================\n",
    "import sys, os, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure project root is importable\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(f'Project root: {PROJECT_ROOT}')\n",
    "print(f'Python: {sys.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77733ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Install dependencies (run once)\n",
    "# ============================================================\n",
    "!pip install -q pandas numpy scikit-learn xgboost torch matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872fda3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 3: Imports\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Project modules\n",
    "from config.settings import (\n",
    "    DATA_DIR, ARTEFACTS_DIR, N_ACTIONS, ACTIONS, ACTION_DELTAS,\n",
    "    STATE_DIM, REWARD_CONFIG, RL_CONFIG\n",
    ")\n",
    "from src.data_extraction import (\n",
    "    build_cohort, extract_all, load_table\n",
    ")\n",
    "from src.preprocessing import preprocess_pipeline\n",
    "from src.mdp_dataset import (\n",
    "    build_episodes, episodes_to_arrays, split_episodes,\n",
    "    StateNormaliser, ALL_STATE_FEATURES\n",
    ")\n",
    "from src.models import (\n",
    "    prepare_xgboost_features_s1, prepare_xgboost_features_s2,\n",
    "    train_xgboost, CQLAgent, SafetyFilter\n",
    ")\n",
    "from src.evaluation import (\n",
    "    evaluate_classifier, off_policy_evaluation,\n",
    "    safety_audit, comparison_table\n",
    ")\n",
    "from src.explainability import (\n",
    "    plot_cohort_summary, plot_mp_distribution,\n",
    "    plot_ventilator_parameters, plot_training_curves,\n",
    "    plot_feature_importance, plot_policy_comparison,\n",
    "    plot_reward_analysis, display_clinical_decision,\n",
    "    plot_action_value_heatmap\n",
    ")\n",
    "\n",
    "# Ensure artefacts dir exists\n",
    "ARTEFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('All modules loaded successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5f9550",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 1: Data Extraction & Cohort Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54792b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 4: Build study cohort\n",
    "# ============================================================\n",
    "print('Building study cohort...')\n",
    "cohort = build_cohort()\n",
    "print(f'\\nCohort size: {len(cohort)} ICU stays')\n",
    "print(f'Hospital mortality: {cohort[\"hospital_mortality\"].mean():.1%}')\n",
    "print(f'Age: {cohort[\"age\"].median():.0f} years (median)')\n",
    "print(f'ICU LOS: {cohort[\"icu_los_hours\"].median():.0f} hours (median)')\n",
    "cohort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 5: Cohort summary visualisation\n",
    "# ============================================================\n",
    "fig = plot_cohort_summary(cohort)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db1aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 6: Extract all clinical data\n",
    "# ============================================================\n",
    "print('Extracting clinical data (ventilator, vitals, labs, anthropometrics)...')\n",
    "raw_data = extract_all(cohort)\n",
    "\n",
    "print('\\nExtracted data shapes:')\n",
    "for key, df in raw_data.items():\n",
    "    print(f'  {key:20s}: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1657c50",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 2: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf4562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 7: Run preprocessing pipeline\n",
    "# ============================================================\n",
    "print('Running preprocessing pipeline...')\n",
    "print('  Steps: outlier removal → merging → standardisation → ')\n",
    "print('         MP calculation → derived variables → hourly resampling')\n",
    "\n",
    "hourly_data = preprocess_pipeline(raw_data, cohort)\n",
    "\n",
    "print(f'\\nHourly data shape: {hourly_data.shape}')\n",
    "print(f'ICU stays with data: {hourly_data[\"icustay_id\"].nunique()}')\n",
    "print(f'Total hours: {len(hourly_data)}')\n",
    "print(f'\\nColumn list:')\n",
    "print(hourly_data.columns.tolist())\n",
    "hourly_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844383f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 8: Mechanical Power analysis\n",
    "# ============================================================\n",
    "fig = plot_mp_distribution(hourly_data, cohort)\n",
    "plt.show()\n",
    "\n",
    "mp_stats = hourly_data['mechanical_power'].describe()\n",
    "print('\\nMechanical Power statistics:')\n",
    "print(mp_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67caba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 9: Ventilator parameter distributions\n",
    "# ============================================================\n",
    "fig = plot_ventilator_parameters(hourly_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7c9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 10: Data quality report\n",
    "# ============================================================\n",
    "print('Data Quality Report')\n",
    "print('=' * 60)\n",
    "missing = hourly_data.isnull().mean().sort_values(ascending=False)\n",
    "print('\\nMissing data fraction per column:')\n",
    "for col, frac in missing.items():\n",
    "    bar = '█' * int(frac * 40)\n",
    "    print(f'  {col:25s} {frac:5.1%} {bar}')\n",
    "\n",
    "# MP availability\n",
    "mp_avail = hourly_data.groupby('icustay_id')['mechanical_power'].apply(\n",
    "    lambda x: x.notna().mean()\n",
    ")\n",
    "print(f'\\nMP availability per stay: {mp_avail.mean():.1%} (mean)')\n",
    "print(f'Stays with >50% MP data: {(mp_avail > 0.5).sum()} / {len(mp_avail)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134bffba",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 3: MDP Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 11: Build episodes\n",
    "# ============================================================\n",
    "print('Building MDP episodes...')\n",
    "episodes = build_episodes(hourly_data, cohort)\n",
    "print(f'\\nTotal episodes: {len(episodes)}')\n",
    "\n",
    "if len(episodes) > 0:\n",
    "    lengths = [len(ep['states']) for ep in episodes]\n",
    "    mort = [ep['patient_info']['hospital_mortality'] for ep in episodes]\n",
    "    print(f'Episode lengths: {np.mean(lengths):.1f} ± {np.std(lengths):.1f} steps')\n",
    "    print(f'Mortality in episodes: {np.mean(mort):.1%}')\n",
    "    \n",
    "    # Action distribution\n",
    "    all_actions = [a for ep in episodes for a in ep['actions']]\n",
    "    print(f'\\nBehaviour policy action distribution:')\n",
    "    for a in range(N_ACTIONS):\n",
    "        count = all_actions.count(a)\n",
    "        frac = count / max(len(all_actions), 1)\n",
    "        print(f'  {ACTIONS[a]:18s}: {count:5d} ({frac:5.1%})')\n",
    "else:\n",
    "    print('WARNING: No episodes constructed. Check data availability.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 12: Reward analysis\n",
    "# ============================================================\n",
    "if len(episodes) > 0:\n",
    "    fig = plot_reward_analysis(episodes)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No episodes to analyse.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 13: Convert to arrays & split\n",
    "# ============================================================\n",
    "if len(episodes) > 0:\n",
    "    print('Converting episodes to arrays...')\n",
    "    feature_list = ALL_STATE_FEATURES\n",
    "    states, actions, rewards, next_states, dones = episodes_to_arrays(\n",
    "        episodes, feature_list\n",
    "    )\n",
    "    print(f'States shape:  {states.shape}')\n",
    "    print(f'Actions shape: {actions.shape}')\n",
    "    print(f'Rewards range: [{rewards.min():.1f}, {rewards.max():.1f}]')\n",
    "    print(f'Terminal steps: {dones.sum()}')\n",
    "    \n",
    "    # Patient-level train/val/test split\n",
    "    train_ep, val_ep, test_ep = split_episodes(episodes)\n",
    "    print(f'\\nSplit: train={len(train_ep)}, val={len(val_ep)}, test={len(test_ep)}')\n",
    "    \n",
    "    # Convert splits\n",
    "    train_s, train_a, train_r, train_ns, train_d = episodes_to_arrays(train_ep, feature_list)\n",
    "    val_s, val_a, val_r, val_ns, val_d = episodes_to_arrays(val_ep, feature_list)\n",
    "    test_s, test_a, test_r, test_ns, test_d = episodes_to_arrays(test_ep, feature_list)\n",
    "    \n",
    "    # Normalise\n",
    "    normaliser = StateNormaliser()\n",
    "    normaliser.fit(train_s)\n",
    "    train_s_n = normaliser.transform(train_s)\n",
    "    val_s_n = normaliser.transform(val_s)\n",
    "    test_s_n = normaliser.transform(test_s)\n",
    "    train_ns_n = normaliser.transform(train_ns)\n",
    "    val_ns_n = normaliser.transform(val_ns)\n",
    "    test_ns_n = normaliser.transform(test_ns)\n",
    "    \n",
    "    print(f'\\nNormalised state dim: {train_s_n.shape[1]}')\n",
    "    print('Dataset construction complete.')\n",
    "else:\n",
    "    print('Skipping — no episodes available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86903d7",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 4: Strategy S1 — Static XGBoost Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 14: S1 — Prepare features\n",
    "# ============================================================\n",
    "if len(episodes) > 0:\n",
    "    print('Preparing S1 features (admission snapshot)...')\n",
    "    \n",
    "    X_train_s1, y_train_s1, feat_s1 = prepare_xgboost_features_s1(train_ep)\n",
    "    X_val_s1, y_val_s1, _ = prepare_xgboost_features_s1(val_ep)\n",
    "    X_test_s1, y_test_s1, _ = prepare_xgboost_features_s1(test_ep)\n",
    "    \n",
    "    print(f'S1 features: {len(feat_s1)}')\n",
    "    print(f'Train: {X_train_s1.shape}, Val: {X_val_s1.shape}, Test: {X_test_s1.shape}')\n",
    "    print(f'Mortality rate — Train: {y_train_s1.mean():.2%}, Test: {y_test_s1.mean():.2%}')\n",
    "else:\n",
    "    print('Skipping — no episodes available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac7e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 15: S1 — Train XGBoost\n",
    "# ============================================================\n",
    "if len(episodes) > 0:\n",
    "    print('Training S1 XGBoost classifier...')\n",
    "    model_s1 = train_xgboost(\n",
    "        X_train_s1, y_train_s1, X_val_s1, y_val_s1,\n",
    "        params={\n",
    "            'max_depth': 4,\n",
    "            'learning_rate': 0.05,\n",
    "            'n_estimators': 200,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'scale_pos_weight': max(1, (1 - y_train_s1.mean()) / max(y_train_s1.mean(), 0.01)),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_s1 = model_s1.predict_proba(X_test_s1)[:, 1]\n",
    "    metrics_s1 = evaluate_classifier(y_test_s1, y_pred_s1)\n",
    "    print('\\nS1 Test Metrics:')\n",
    "    for k, v in metrics_s1.items():\n",
    "        if isinstance(v, (int, float)):\n",
    "            print(f'  {k:20s}: {v:.4f}')\n",
    "        else:\n",
    "            print(f'  {k:20s}: {v}')\n",
    "    \n",
    "    # Feature importance\n",
    "    fig = plot_feature_importance(model_s1, feat_s1, top_n=min(15, len(feat_s1)))\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Skipping — no episodes available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e52474",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 5: Strategy S2 — Time-Window XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c3ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 16: S2 — Prepare features & train\n",
    "# ============================================================\n",
    "if len(episodes) > 0:\n",
    "    print('Preparing S2 features (multi-timepoint + trajectory stats)...')\n",
    "    \n",
    "    X_train_s2, y_train_s2, feat_s2 = prepare_xgboost_features_s2(\n",
    "        train_ep, feature_list=feature_list, windows=[0, 6, 12, 24]\n",
    "    )\n",
    "    X_val_s2, y_val_s2, _ = prepare_xgboost_features_s2(\n",
    "        val_ep, feature_list=feature_list, windows=[0, 6, 12, 24]\n",
    "    )\n",
    "    X_test_s2, y_test_s2, _ = prepare_xgboost_features_s2(\n",
    "        test_ep, feature_list=feature_list, windows=[0, 6, 12, 24]\n",
    "    )\n",
    "    \n",
    "    print(f'S2 features: {len(feat_s2)}')\n",
    "    print(f'Train: {X_train_s2.shape}, Val: {X_val_s2.shape}, Test: {X_test_s2.shape}')\n",
    "    \n",
    "    print('\\nTraining S2 XGBoost classifier...')\n",
    "    model_s2 = train_xgboost(\n",
    "        X_train_s2, y_train_s2, X_val_s2, y_val_s2,\n",
    "        params={\n",
    "            'max_depth': 5,\n",
    "            'learning_rate': 0.05,\n",
    "            'n_estimators': 300,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'scale_pos_weight': max(1, (1 - y_train_s2.mean()) / max(y_train_s2.mean(), 0.01)),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    y_pred_s2 = model_s2.predict_proba(X_test_s2)[:, 1]\n",
    "    metrics_s2 = evaluate_classifier(y_test_s2, y_pred_s2)\n",
    "    print('\\nS2 Test Metrics:')\n",
    "    for k, v in metrics_s2.items():\n",
    "        if isinstance(v, (int, float)):\n",
    "            print(f'  {k:20s}: {v:.4f}')\n",
    "        else:\n",
    "            print(f'  {k:20s}: {v}')\n",
    "    \n",
    "    fig = plot_feature_importance(model_s2, feat_s2, top_n=min(15, len(feat_s2)))\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Skipping — no episodes available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d4a3c7",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 6: Strategy S3 — Conservative Q-Learning (CQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4363928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 17: Initialise CQL Agent\n",
    "# ============================================================\n",
    "if len(episodes) > 0:\n",
    "    from src.models import TORCH_AVAILABLE\n",
    "    \n",
    "    if TORCH_AVAILABLE:\n",
    "        agent = CQLAgent(\n",
    "            state_dim=STATE_DIM,\n",
    "            n_actions=N_ACTIONS,\n",
    "            hidden_dim=RL_CONFIG.get('hidden_dim', 256),\n",
    "            lr=RL_CONFIG.get('lr', 1e-4),\n",
    "            gamma=RL_CONFIG.get('gamma', 0.99),\n",
    "            cql_alpha=RL_CONFIG.get('cql_alpha', 1.0),\n",
    "            tau=RL_CONFIG.get('tau', 0.005),\n",
    "            batch_size=RL_CONFIG.get('batch_size', 256),\n",
    "            dropout=0.3,\n",
    "        )\n",
    "        print(f'CQL Agent initialised on {agent.device}')\n",
    "        print(f'  State dim:  {STATE_DIM}')\n",
    "        print(f'  Actions:    {N_ACTIONS}')\n",
    "        print(f'  Hidden dim: {RL_CONFIG.get(\"hidden_dim\", 256)}')\n",
    "        print(f'  CQL alpha:  {RL_CONFIG.get(\"cql_alpha\", 1.0)}')\n",
    "        print(f'  LR:         {RL_CONFIG.get(\"lr\", 1e-4)}')\n",
    "    else:\n",
    "        print('WARNING: PyTorch not available — skipping CQL agent initialisation.')\n",
    "        print('Strategies S1 and S2 (XGBoost) will still work.')\n",
    "else:\n",
    "    print('Skipping — no episodes available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e4a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 18: Train CQL agent\n",
    "# ============================================================\n",
    "if len(episodes) > 0:\n",
    "    n_epochs = RL_CONFIG.get('n_epochs', 50)\n",
    "    batch_size = RL_CONFIG.get('batch_size', 256)\n",
    "    \n",
    "    print(f'Training CQL for {n_epochs} epochs (batch_size={batch_size})...')\n",
    "    history = agent.train(\n",
    "        states=train_s_n,\n",
    "        actions=train_a,\n",
    "        rewards=train_r,\n",
    "        next_states=train_ns_n,\n",
    "        dones=train_d,\n",
    "        n_epochs=n_epochs,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    print(f'\\nFinal loss: {history[\"loss\"][-1]:.4f}')\n",
    "    print(f'Final Q-mean: {history[\"q_mean\"][-1]:.4f}')\n",
    "    \n",
    "    # Save model\n",
    "    agent.save(ARTEFACTS_DIR / 'cql_agent.pt')\n",
    "    print(f'Model saved to {ARTEFACTS_DIR / \"cql_agent.pt\"}')\n",
    "else:\n",
    "    print('Skipping — no episodes available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 19: Training curves\n",
    "# ============================================================\n",
    "if len(episodes) > 0:\n",
    "    fig = plot_training_curves(history)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Skipping — no training history.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f4fe8b",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 7: Evaluation & Off-Policy Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f07c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 20: CQL – Action distribution on test set\n",
    "# ============================================================\n",
    "if len(episodes) > 0:\n",
    "    print('CQL policy evaluation on test set...')\n",
    "    \n",
    "    # Get CQL actions for test transitions\n",
    "    cql_actions = []\n",
    "    cql_q_values = []\n",
    "    for i in range(len(test_s_n)):\n",
    "        pred = agent.predict(test_s_n[i])\n",
    "        cql_actions.append(pred['action'])\n",
    "        cql_q_values.append(pred['q_values'])\n",
    "    \n",
    "    cql_actions = np.array(cql_actions)\n",
    "    \n",
    "    # Compare action distributions\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    fig.suptitle('Action Distribution: Behaviour vs. CQL Policy', fontsize=14)\n",
    "    \n",
    "    for ax, actions_arr, title in [\n",
    "        (axes[0], test_a, 'Clinician (Behaviour)'),\n",
    "        (axes[1], cql_actions, 'CQL Policy (Learned)'),\n",
    "    ]:\n",
    "        counts = [np.sum(actions_arr == a) for a in range(N_ACTIONS)]\n",
    "        colors = ['#2ecc71', '#85c1e9', '#95a5a6', '#f5b041', '#c0392b']\n",
    "        ax.bar(range(N_ACTIONS), counts, color=colors)\n",
    "        ax.set_xticks(range(N_ACTIONS))\n",
    "        ax.set_xticklabels([ACTIONS[a] for a in range(N_ACTIONS)], rotation=30, ha='right')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ARTEFACTS_DIR / 'action_distributions.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Agreement rate\n",
    "    agreement = (cql_actions == test_a).mean()\n",
    "    print(f'\\nPolicy agreement with clinicians: {agreement:.1%}')\n",
    "else:\n",
    "    print('Skipping.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d6d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 21: Off-Policy Evaluation\n",
    "# ============================================================\n",
    "if len(episodes) > 0:\n",
    "    print('Running Off-Policy Evaluation (OPE)...')\n",
    "    ope_results = off_policy_evaluation(\n",
    "        agent=agent,\n",
    "        episodes=test_ep,\n",
    "        feature_list=feature_list,\n",
    "        gamma=RL_CONFIG.get('gamma', 0.99)\n",
    "    )\n",
    "    \n",
    "    print('\\nOPE Results:')\n",
    "    for k, v in ope_results.items():\n",
    "        if isinstance(v, float):\n",
    "            print(f'  {k:30s}: {v:.4f}')\n",
    "        else:\n",
    "            print(f'  {k:30s}: {v}')\n",
    "else:\n",
    "    print('Skipping.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a79b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 22: Safety audit\n",
    "# ============================================================\n",
    "if len(episodes) > 0:\n",
    "    print('Running safety audit...')\n",
    "    safety_filter = SafetyFilter()\n",
    "    \n",
    "    safety_results = safety_audit(\n",
    "        agent=agent,\n",
    "        episodes=test_ep,\n",
    "        feature_list=feature_list,\n",
    "        safety_filter=safety_filter\n",
    "    )\n",
    "    \n",
    "    print('\\nSafety Audit Results:')\n",
    "    for k, v in safety_results.items():\n",
    "        if isinstance(v, dict):\n",
    "            print(f'  {k}:')\n",
    "            for sk, sv in v.items():\n",
    "                print(f'    {sk}: {sv}')\n",
    "        else:\n",
    "            print(f'  {k:30s}: {v}')\n",
    "else:\n",
    "    print('Skipping.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9807cc2d",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 8: Strategy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9e6aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 23: Comparison table\n",
    "# ============================================================\n",
    "if len(episodes) > 0:\n",
    "    results_list = []\n",
    "    \n",
    "    # S1\n",
    "    if 'metrics_s1' in dir():\n",
    "        s1_entry = {'strategy': 'S1_Static_XGBoost'}\n",
    "        s1_entry.update(metrics_s1)\n",
    "        results_list.append(s1_entry)\n",
    "    \n",
    "    # S2\n",
    "    if 'metrics_s2' in dir():\n",
    "        s2_entry = {'strategy': 'S2_TimeWindow_XGBoost'}\n",
    "        s2_entry.update(metrics_s2)\n",
    "        results_list.append(s2_entry)\n",
    "    \n",
    "    # S3 – CQL (use OPE metrics)\n",
    "    if 'ope_results' in dir():\n",
    "        s3_entry = {'strategy': 'S3_CQL_RL'}\n",
    "        s3_entry['dm_estimate'] = ope_results.get('dm_estimate', np.nan)\n",
    "        s3_entry['agreement_rate'] = ope_results.get('agreement_rate', np.nan)\n",
    "        results_list.append(s3_entry)\n",
    "    \n",
    "    if results_list:\n",
    "        comp_df = pd.DataFrame(results_list).set_index('strategy')\n",
    "        print('Strategy Comparison')\n",
    "        print('=' * 70)\n",
    "        print(comp_df.to_string())\n",
    "        comp_df.to_csv(ARTEFACTS_DIR / 'strategy_comparison.csv')\n",
    "        print(f'\\nSaved to {ARTEFACTS_DIR / \"strategy_comparison.csv\"}')\n",
    "    else:\n",
    "        print('No results to compare.')\n",
    "else:\n",
    "    print('Skipping.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1943eb",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 9: Policy Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d6216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 24: Behaviour vs. learned policy trajectories\n",
    "# ============================================================\n",
    "if len(episodes) > 0 and 'agent' in dir():\n",
    "    fig = plot_policy_comparison(\n",
    "        episodes=test_ep[:3],\n",
    "        agent=agent,\n",
    "        feature_list=feature_list,\n",
    "        n_episodes=min(3, len(test_ep)),\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Skipping.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf702ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 25: Q-value heatmap\n",
    "# ============================================================\n",
    "if len(episodes) > 0 and 'agent' in dir():\n",
    "    fig = plot_action_value_heatmap(agent, test_ep, feature_list=feature_list)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Skipping.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b494459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 26: Clinical decision display (example)\n",
    "# ============================================================\n",
    "if len(episodes) > 0 and 'agent' in dir():\n",
    "    # Pick a sample state from the test set\n",
    "    sample_ep = test_ep[0]\n",
    "    sample_state = sample_ep['states'][0]\n",
    "    \n",
    "    from src.mdp_dataset import flatten_state\n",
    "    s = flatten_state(sample_state, feature_list)\n",
    "    s_n = normaliser.transform(s.reshape(1, -1))[0]\n",
    "    prediction = agent.predict(s_n)\n",
    "    \n",
    "    # Safety check\n",
    "    safe_action, alert = safety_filter.check(sample_state, prediction['action'])\n",
    "    if safe_action != prediction['action']:\n",
    "        alert_msg = f'Action overridden: {ACTIONS[prediction[\"action\"]]} → {ACTIONS[safe_action]} ({alert})'\n",
    "    else:\n",
    "        alert_msg = None\n",
    "    \n",
    "    display_clinical_decision(sample_state, prediction, safety_alert=alert_msg)\n",
    "else:\n",
    "    print('Skipping.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b8ce7e",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 10: Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bcaa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 27: Pipeline summary\n",
    "# ============================================================\n",
    "print('=' * 60)\n",
    "print('  PIPELINE SUMMARY')\n",
    "print('=' * 60)\n",
    "\n",
    "print(f'\\nData:')\n",
    "print(f'  Cohort size:      {len(cohort)} ICU stays')\n",
    "if len(episodes) > 0:\n",
    "    print(f'  Episodes built:   {len(episodes)}')\n",
    "    print(f'  Total transitions: {sum(len(ep[\"states\"]) for ep in episodes)}')\n",
    "    print(f'  State dimension:  {STATE_DIM}')\n",
    "\n",
    "print(f'\\nClinical:')\n",
    "print(f'  Mortality rate:   {cohort[\"hospital_mortality\"].mean():.1%}')\n",
    "if 'mp_stats' in dir():\n",
    "    print(f'  Median MP:        {mp_stats[\"50%\"]:.1f} J/min')\n",
    "\n",
    "print(f'\\nModels trained:')\n",
    "if 'model_s1' in dir():\n",
    "    auroc_s1 = metrics_s1.get(\"auroc\", \"N/A\")\n",
    "    if isinstance(auroc_s1, float):\n",
    "        auroc_s1 = f'{auroc_s1:.4f}'\n",
    "    print(f'  S1 -- Static XGBoost (AUROC: {auroc_s1})')\n",
    "if 'model_s2' in dir():\n",
    "    auroc_s2 = metrics_s2.get(\"auroc\", \"N/A\")\n",
    "    if isinstance(auroc_s2, float):\n",
    "        auroc_s2 = f'{auroc_s2:.4f}'\n",
    "    print(f'  S2 -- Time-Window XGBoost (AUROC: {auroc_s2})')\n",
    "if 'agent' in dir():\n",
    "    print(f'  S3 -- CQL RL Agent (trained {n_epochs} epochs)')\n",
    "\n",
    "print(f'\\nArtefacts saved to: {ARTEFACTS_DIR}')\n",
    "import os\n",
    "for f in sorted(os.listdir(ARTEFACTS_DIR)):\n",
    "    size = os.path.getsize(ARTEFACTS_DIR / f) / 1024\n",
    "    print(f'  {f:40s} {size:6.1f} KB')\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('  Pipeline complete.')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad60d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 28: Next steps\n",
    "# ============================================================\n",
    "print('''\n",
    "NEXT STEPS FOR PRODUCTION\n",
    "=========================\n",
    "\n",
    "1. Scale to full MIMIC-III/IV (>15,000 ventilated ICU stays)\n",
    "   - Current demo has only 100 patients\n",
    "   - Adjust min_vent_hours back to 24h\n",
    "   - Enable proper cross-validation\n",
    "\n",
    "2. Causal inference additions\n",
    "   - Add propensity score estimation\n",
    "   - Implement doubly-robust OPE estimators\n",
    "   - DAG-based confounding analysis\n",
    "\n",
    "3. Model improvements\n",
    "   - Hyperparameter tuning (Optuna/Ray)\n",
    "   - Ensemble of CQL agents (bagging)\n",
    "   - Recurrent state encoder (LSTM/Transformer)\n",
    "\n",
    "4. Clinical validation\n",
    "   - Expert clinician review of recommendations\n",
    "   - Subgroup fairness analysis\n",
    "   - Prospective simulation study\n",
    "\n",
    "5. Deployment\n",
    "   - Real-time inference API\n",
    "   - EHR integration (FHIR/HL7)\n",
    "   - Monitoring dashboard\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
